---
title: "XGBoost Explainability using inTrees"
author: "Siddharth Jain"
date: "24 June 2019"
output: rmarkdown::github_document
---

## Imports
```{r, warning=FALSE,message=FALSE}
library('inTrees')
library('dplyr')
library('Matrix')
library('caTools')
library('xgboost')
```

## Reading the data
```{r}
shrooms = read.csv('mushrooms.csv')
```
Omitting NA (empty) rows
```{r}
shrooms = na.omit(shrooms)
```

**Our output is the class of the mushroom. Either edible (e) or poisonous (p)**

Converting the class to characters
```{r}
shrooms['class'] %>% mutate_if(is.factor, as.character) -> shrooms['class']
```
Converting the classes ('p'/'e') to numeric value
```{r}
a = 0
for (i in unique(shrooms$class)) {
  shrooms$class[shrooms$class == i] = a
  a = a + 1
}
```
Setting seed for our train/test split on the given dataset
```{r}
set.seed(42)
```
**Splitting into train and test datasets (0.75 ratio)**
```{r}
sample = sample.split(shrooms, SplitRatio = 0.75)
train1 = subset(shrooms, sample == TRUE)
test1 = subset(shrooms, sample == FALSE)
```
Our output variable is in the first column (class)
```{r}
output_vector = train1[, 1]
```
For future accuracy testing
```{r}
real_output = test1[, 1]
```
Our model is classifying into two classes (poisonous or edible)
```{r}
number_classes = 2
```
### Making the model
```{r}
xgbmodel = xgboost(
  data = data.matrix(train1[, -1]),
  label = output_vector,
  nfold = 100,
  max.depth = 4,
  nrounds = 10,
  eta = 1,
  nthread = 4,
  objective = 'multi:softprob',
  num_class = number_classes
)
```

### Testing Model Accuracy

**Finding model predictions**
```{r}
pred <- predict(xgbmodel, data.matrix(test1[, -1]))
```
Rounding because we need 0 or 1 values (binary classification)
```{r}
pred <- lapply(pred, round)
```
Finding the sum of all places where prediction is the same as the real output, and getting accuracy by simple division
```{r}
print(sum(pred == real_output) / length(real_output) * 100)
```
We get pretty high accuracy on our model. 

**Let us see if the rules extracted from this model (using inTrees) give a comparable accuracy**

Now we know that our model is performing well, but if someone wants to know *why* a mushroom is poisonous, what do we say?

We can use feature importance, and also use inTrees to see the exact rules that are defining the tree ensemble used by XGBoost.

#### Finding feature importance
```{r}
importance <-
  xgb.importance(feature_names = colnames(data.matrix(train1[, -1])), model = xgbmodel)
print(head(importance))
```


## Using inTrees

#### Making a tree list from the XGB model:
```{r}
tree_list = XGB2List(xgbmodel, data.matrix(train1[, -1]))
```
**Extracting rules from the tree list:**
```{r}
exec = extractRules(tree_list, data.matrix(train1[, -1]))
```
**Getting rule metrics from the rules:**
```{r}
ruleMetric <- getRuleMetric(exec, data.matrix(train1[, -1]), output_vector)
knitr::kable(head(ruleMetric), floating.environment="sidewaystable")
```


Rule Metric explanation:

* len: No. of variable-value pairs in that condition
* freq: %age of data satisfying the condition
* pred: Outcome
* err: Error rate


#### Pruning the rules generated. This removes repeated, redundant rules
```{r}
ruleMetric2 <- pruneRule(ruleMetric, data.matrix(train1[, -1]), output_vector)
```

#### Selecting the important rules using a regularized random forest (refer paper for formulae)
```{r}
ruleMetric3 <- selectRuleRRF(ruleMetric2, data.matrix(train1[, -1]), output_vector)
```
This step greatly reduces the number of rules by only selecting the important ones.


### Building a learner based on our rules. We can use this to predict values and see accuracy of our extracted rules
```{r}
learner <- buildLearner(ruleMetric3, data.matrix(train1[, -1]), output_vector)
knitr::kable(learner, floating.environment="sidewaystable")
```

### Using the learner to predict values:
```{r}
applied <- applyLearner(learner, data.matrix(test1[, -1]))
```
**Checking the accuracy of this learner built from the rules:**
```{r}
print(sum(real_output == applied) / length(real_output) * 100)
```
**We get around 95% accuracy, which is pretty good for such a small number of rules**

Our learner doesn't have condition names, adding those to make it human readable (using presentRules)

```{r}
Simp_Learner <- presentRules(ruleMetric3, colnames(train1[, -1]))
knitr::kable(Simp_Learner, floating.environment="sidewaystable")
```

**Hence we have used the inTrees library to easily understand the rules defining a decision for an XGBoost ensemble model.**

Thank [Houtao Deng](https://www.linkedin.com/in/houtao-d-48902711/) for the inTrees library


